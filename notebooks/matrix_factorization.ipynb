{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix (R):\n",
      "[[5 3 0 1]\n",
      " [4 0 0 1]\n",
      " [1 1 0 5]\n",
      " [1 0 0 4]\n",
      " [0 1 5 4]]\n",
      "\n",
      "Reconstructed Matrix (R_k) using top 2 latent features:\n",
      "[[ 5.13406479  1.90612125 -0.72165061  1.5611261 ]\n",
      " [ 3.43308995  1.28075331 -0.45629689  1.08967559]\n",
      " [ 1.54866643  1.0449763   1.78873709  3.96755551]\n",
      " [ 1.17598269  0.80359806  1.40136891  3.08786154]\n",
      " [-0.44866693  0.5443561   3.09799526  5.15263893]]\n",
      "\n",
      "Predicted rating for user 0 and item 3:\n",
      "1.56112610151169\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example user-item interaction matrix (ratings matrix)\n",
    "# Rows represent users, columns represent items, and values represent ratings\n",
    "R = np.array([\n",
    "    [5, 3, 0, 1],\n",
    "    [4, 0, 0, 1],\n",
    "    [1, 1, 0, 5],\n",
    "    [1, 0, 0, 4],\n",
    "    [0, 1, 5, 4],\n",
    "])\n",
    "\n",
    "# Number of latent features\n",
    "k = 2\n",
    "\n",
    "# Perform Singular Value Decomposition\n",
    "U, sigma, Vt = np.linalg.svd(R, full_matrices=False)\n",
    "\n",
    "# Keep only the top k singular values\n",
    "U_k = U[:, :k]\n",
    "sigma_k = np.diag(sigma[:k])\n",
    "Vt_k = Vt[:k, :]\n",
    "\n",
    "# Reconstruct the matrix using only the top k singular values\n",
    "R_k = np.dot(np.dot(U_k, sigma_k), Vt_k)\n",
    "\n",
    "print(\"Original Matrix (R):\")\n",
    "print(R)\n",
    "print(\"\\nReconstructed Matrix (R_k) using top {} latent features:\".format(k))\n",
    "print(R_k)\n",
    "\n",
    "# Prediction for a specific user-item pair\n",
    "user_index = 0  # First user\n",
    "item_index = 3  # Third item\n",
    "predicted_rating = np.dot(np.dot(U_k[user_index, :], sigma_k), Vt_k[:, item_index])\n",
    "print(\"\\nPredicted rating for user {} and item {}:\".format(user_index, item_index))\n",
    "print(predicted_rating)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query-LLM Performance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Matrix:\n",
      "[[ 2.  3.  3.  3.]\n",
      " [ 1.  8.  4.  1.]\n",
      " [ 3.  9.  4.  2.]\n",
      " [ 5.  8.  6.  5.]\n",
      " [ 5.  4. 10.  3.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample queries\n",
    "queries = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Explain quantum computing\",\n",
    "    \"Write a poem about spring\",\n",
    "    \"Summarize the plot of Hamlet\",\n",
    "    \"How does photosynthesis work?\"\n",
    "]\n",
    "\n",
    "# Sample LLMs\n",
    "llms = [\"GPT-4\", \"BERT\", \"T5\", \"LLaMA\"]\n",
    "\n",
    "# Hypothetical function to evaluate LLM performance on a query\n",
    "def evaluate_llm_performance(query, llm):\n",
    "    # This function should return a performance score for the given query and LLM\n",
    "    # For demonstration, we'll use random scores\n",
    "    np.random.seed(hash(query + llm) % (2**32))\n",
    "    return np.random.randint(1, 11)  # Random score between 1 and 10\n",
    "\n",
    "# Generate the performance matrix\n",
    "performance_matrix = np.zeros((len(queries), len(llms)))\n",
    "\n",
    "for i, query in enumerate(queries):\n",
    "    for j, llm in enumerate(llms):\n",
    "        performance_matrix[i, j] = evaluate_llm_performance(query, llm)\n",
    "\n",
    "print(\"Performance Matrix:\")\n",
    "print(performance_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Query-LLM Performance - Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted performance scores for the query:\n",
      "'Explain the theory of relativity'\n",
      "GPT-4: 3.29\n",
      "BERT: 7.54\n",
      "T5: 5.35\n",
      "LLaMA: 2.85\n",
      "\n",
      "Routing to: BERT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Convert queries to TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "query_vectors = vectorizer.fit_transform(queries)\n",
    "\n",
    "# Number of latent factors\n",
    "k = 2\n",
    "\n",
    "# Perform SVD on the performance matrix\n",
    "U, sigma, Vt = np.linalg.svd(performance_matrix, full_matrices=False)\n",
    "\n",
    "# Keep only top k factors\n",
    "U_k = U[:, :k]\n",
    "sigma_k = np.diag(sigma[:k])\n",
    "Vt_k = Vt[:k, :]\n",
    "\n",
    "# Function to predict performance for a new query\n",
    "def predict_performance(new_query):\n",
    "    new_vector = vectorizer.transform([new_query])\n",
    "    similarities = cosine_similarity(new_vector, query_vectors)\n",
    "    query_factors = np.dot(similarities, U_k)\n",
    "    predicted_scores = np.dot(np.dot(query_factors, sigma_k), Vt_k)\n",
    "    return predicted_scores[0]\n",
    "\n",
    "# Example usage\n",
    "new_query = \"Explain the theory of relativity\"\n",
    "predicted_scores = predict_performance(new_query)\n",
    "\n",
    "print(\"Predicted performance scores for the query:\")\n",
    "print(f\"'{new_query}'\")\n",
    "for llm, score in zip(llms, predicted_scores):\n",
    "    print(f\"{llm}: {score:.2f}\")\n",
    "\n",
    "# Route to the best LLM\n",
    "best_llm = llms[np.argmax(predicted_scores)]\n",
    "print(f\"\\nRouting to: {best_llm}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Least Squares (ALS) for matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted performance scores for the query:\n",
      "'Explain the theory of relativity'\n",
      "GPT-4: 0.55\n",
      "BERT: -0.19\n",
      "T5: 0.39\n",
      "LLaMA: 0.50\n",
      "\n",
      "Routing to: GPT-4\n",
      "\n",
      "Predictions for multiple new queries:\n",
      "\n",
      "Query: 'What are the main causes of climate change?'\n",
      "Routed to: GPT-4\n",
      "Scores:\n",
      "  GPT-4: 0.75\n",
      "  BERT: -0.27\n",
      "  T5: 0.54\n",
      "  LLaMA: 0.69\n",
      "\n",
      "Query: 'How does machine learning work?'\n",
      "Routed to: BERT\n",
      "Scores:\n",
      "  GPT-4: 0.30\n",
      "  BERT: 1.54\n",
      "  T5: 0.28\n",
      "  LLaMA: 0.37\n",
      "\n",
      "Query: 'Explain the process of photosynthesis'\n",
      "Routed to: GPT-4\n",
      "Scores:\n",
      "  GPT-4: 0.56\n",
      "  BERT: 0.33\n",
      "  T5: 0.42\n",
      "  LLaMA: 0.54\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def als_matrix_factorization(R, k, num_iterations=10, lambda_reg=0.1):\n",
    "    \"\"\"\n",
    "    Perform matrix factorization using Alternating Least Squares (ALS).\n",
    "    \n",
    "    Args:\n",
    "    R: The input matrix (queries x LLMs)\n",
    "    k: Number of latent factors\n",
    "    num_iterations: Number of iterations to perform\n",
    "    lambda_reg: Regularization parameter\n",
    "    \n",
    "    Returns:\n",
    "    P, Q: Factorized matrices such that R â‰ˆ P * Q.T\n",
    "    \"\"\"\n",
    "    m, n = R.shape\n",
    "    P = np.random.rand(m, k)\n",
    "    Q = np.random.rand(n, k)\n",
    "    \n",
    "    # Create a mask for non-zero elements\n",
    "    mask = R != 0\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        # Update P\n",
    "        for i in range(m):\n",
    "            if np.sum(mask[i]) > 0:\n",
    "                Q_i = Q[mask[i], :]\n",
    "                R_i = R[i, mask[i]]\n",
    "                A = Q_i.T.dot(Q_i) + lambda_reg * np.eye(k)\n",
    "                b = Q_i.T.dot(R_i)\n",
    "                P[i] = np.linalg.solve(A, b)\n",
    "        \n",
    "        # Update Q\n",
    "        for j in range(n):\n",
    "            if np.sum(mask[:, j]) > 0:\n",
    "                P_j = P[mask[:, j], :]\n",
    "                R_j = R[mask[:, j], j]\n",
    "                A = P_j.T.dot(P_j) + lambda_reg * np.eye(k)\n",
    "                b = P_j.T.dot(R_j)\n",
    "                Q[j] = np.linalg.solve(A, b)\n",
    "    \n",
    "    return P, Q\n",
    "\n",
    "# Sample queries and LLMs\n",
    "queries = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Explain quantum computing\",\n",
    "    \"Write a poem about spring\",\n",
    "    \"Summarize the plot of Hamlet\",\n",
    "    \"How does photosynthesis work?\"\n",
    "]\n",
    "\n",
    "llms = [\"GPT-4\", \"BERT\", \"T5\", \"LLaMA\"]\n",
    "\n",
    "# Sample performance matrix (queries x LLMs)\n",
    "R = np.array([\n",
    "    [9, 7, 5, 8],\n",
    "    [8, 6, 7, 9],\n",
    "    [9, 4, 6, 8],\n",
    "    [8, 5, 7, 8],\n",
    "    [7, 8, 6, 7]\n",
    "])\n",
    "\n",
    "# Number of latent factors\n",
    "k = 2\n",
    "\n",
    "# Perform matrix factorization\n",
    "P, Q = als_matrix_factorization(R, k)\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "query_vectors = vectorizer.fit_transform(queries)\n",
    "\n",
    "# Use TruncatedSVD to reduce dimensionality of TF-IDF vectors to k\n",
    "svd = TruncatedSVD(n_components=k)\n",
    "query_latent_factors = svd.fit_transform(query_vectors)\n",
    "\n",
    "# Function to convert a new query to latent factor space\n",
    "def query_to_latent_factor(new_query):\n",
    "    new_vector = vectorizer.transform([new_query])\n",
    "    return svd.transform(new_vector)\n",
    "\n",
    "# Function to predict performance for a new query\n",
    "def predict_performance(query_vector, Q):\n",
    "    return np.dot(query_vector, Q.T)\n",
    "\n",
    "# Example: Predict performance for a new query\n",
    "new_query = \"Explain the theory of relativity\"\n",
    "new_query_vector = query_to_latent_factor(new_query)\n",
    "predicted_scores = predict_performance(new_query_vector, Q)\n",
    "\n",
    "print(\"Predicted performance scores for the query:\")\n",
    "print(f\"'{new_query}'\")\n",
    "for llm, score in zip(llms, predicted_scores[0]):\n",
    "    print(f\"{llm}: {score:.2f}\")\n",
    "\n",
    "# Route to the best LLM\n",
    "best_llm = llms[np.argmax(predicted_scores)]\n",
    "print(f\"\\nRouting to: {best_llm}\")\n",
    "\n",
    "# Demonstrate with multiple new queries\n",
    "new_queries = [\n",
    "    \"What are the main causes of climate change?\",\n",
    "    \"How does machine learning work?\",\n",
    "    \"Explain the process of photosynthesis\"\n",
    "]\n",
    "\n",
    "print(\"\\nPredictions for multiple new queries:\")\n",
    "for query in new_queries:\n",
    "    query_vector = query_to_latent_factor(query)\n",
    "    scores = predict_performance(query_vector, Q)\n",
    "    best_llm = llms[np.argmax(scores)]\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    print(f\"Routed to: {best_llm}\")\n",
    "    print(\"Scores:\")\n",
    "    for llm, score in zip(llms, scores[0]):\n",
    "        print(f\"  {llm}: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sleep and Car Data - Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/Vt.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse.linalg import svds\n",
    "import joblib\n",
    "\n",
    "# Load datasets\n",
    "sleep_data = pd.read_json('../data/raw/training_qna_sleep.json')\n",
    "car_data = pd.read_json('../data/raw/training_qna_car.json')\n",
    "\n",
    "# Extract questions and add categories\n",
    "sleep_data['question'] = sleep_data['qna'].apply(lambda x: x['question'])\n",
    "sleep_data['category'] = 'sleep'\n",
    "car_data['question'] = car_data['qna'].apply(lambda x: x['question'])\n",
    "car_data['category'] = 'car'\n",
    "\n",
    "# Combine datasets\n",
    "data = pd.concat([sleep_data, car_data], ignore_index=True)\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(data['question'])\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "interaction_matrix = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "interaction_matrix['category'] = data['category'].apply(lambda x: 1 if x == 'sleep' else 0)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(interaction_matrix, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform matrix factorization using SVD\n",
    "k = 10  # number of latent factors\n",
    "U, sigma, Vt = svds(train_data.drop('category', axis=1).values, k=k)\n",
    "\n",
    "# Convert sigma to a diagonal matrix\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Save the components\n",
    "joblib.dump(vectorizer, '../models/vectorizer.pkl')\n",
    "joblib.dump(U, '../models/U.pkl')\n",
    "joblib.dump(sigma, '../models/sigma.pkl')\n",
    "joblib.dump(Vt, '../models/Vt.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the impact of sleep deprivation on driving?\n",
      "Classification: sleep\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classify_query(query, U, sigma, Vt, vectorizer, train_data):\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    \n",
    "    # Project the query vector into the latent space\n",
    "    query_latent = query_vector.dot(Vt.T)\n",
    "    \n",
    "    # Compute the mean latent vectors for sleep and car categories\n",
    "    sleep_latent = train_data[train_data['category'] == 1].drop('category', axis=1).values.mean(axis=0).dot(Vt.T)\n",
    "    car_latent = train_data[train_data['category'] == 0].drop('category', axis=1).values.mean(axis=0).dot(Vt.T)\n",
    "    \n",
    "    # Ensure all vectors are 2D\n",
    "    query_latent = query_latent.reshape(1, -1)\n",
    "    sleep_latent = sleep_latent.reshape(1, -1)\n",
    "    car_latent = car_latent.reshape(1, -1)\n",
    "    \n",
    "    # Compute the similarity scores using cosine similarity\n",
    "    sleep_score = np.dot(query_latent, sleep_latent.T) / (np.linalg.norm(query_latent) * np.linalg.norm(sleep_latent))\n",
    "    car_score = np.dot(query_latent, car_latent.T) / (np.linalg.norm(query_latent) * np.linalg.norm(car_latent))\n",
    "    \n",
    "    return 'sleep' if sleep_score > car_score else 'car'\n",
    "\n",
    "# Test the classifier\n",
    "test_query = \"What is the impact of sleep deprivation on driving?\"\n",
    "classification = classify_query(test_query, U, sigma, Vt, vectorizer, train_data)\n",
    "print(f\"Query: {test_query}\")\n",
    "print(f\"Classification: {classification}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What's the impact of sleep deprivation on cognitive function?\n",
      "Classified as: sleep\n",
      "\n",
      "Query: Can you explain the history of the internal combustion engine?\n",
      "Classified as: car\n",
      "\n",
      "Query: How does REM sleep affect memory consolidation?\n",
      "Classified as: sleep\n",
      "\n",
      "Query: What are the main components of an electric vehicle's drivetrain?\n",
      "Classified as: car\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What's the impact of sleep deprivation on cognitive function?\",\n",
    "    \"Can you explain the history of the internal combustion engine?\",\n",
    "    \"How does REM sleep affect memory consolidation?\",\n",
    "    \"What are the main components of an electric vehicle's drivetrain?\",\n",
    "]\n",
    "\n",
    "# Test the classifier\n",
    "for query in queries:\n",
    "    result = classify_query(query, U, sigma, Vt, vectorizer, train_data)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Classified as: {result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "donut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
