{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: d:\\WORK\\Personal\\Multi-Model-LLM-Router\\data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../data\")\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data saved to processed\\train_sleep.csv.\n",
      "Testing data saved to processed\\test_sleep.csv.\n",
      "Training data saved to processed\\train_car.csv.\n",
      "Testing data saved to processed\\test_car.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "SLEEP_DATA_FILE = \"raw/training_qna_sleep.json\"\n",
    "CAR_DATA_FILE = \"raw/training_qna_car.json\"\n",
    "OUTPUT_FOLDER = \"processed\"\n",
    "TRAIN_SLEEP_FILE = \"train_sleep.csv\"\n",
    "TRAIN_CAR_FILE = \"train_car.csv\"\n",
    "TEST_SLEEP_FILE = \"test_sleep.csv\"\n",
    "TEST_CAR_FILE = \"test_car.csv\"\n",
    "TRAIN_RATIO = 0.9\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading en_core_web_sm model...\")\n",
    "    spacy.cli.download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    return \" \".join(token.text for token in nlp(text) if not token.is_space)\n",
    "\n",
    "\n",
    "def process_json_file(json_file, output_folder, train_file, test_file, train_ratio):\n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load data\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Shuffle the data\n",
    "    random.shuffle(data[\"qna\"])\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    split_index = int(len(data[\"qna\"]) * train_ratio)\n",
    "    train_data = data[\"qna\"][:split_index]\n",
    "    test_data = data[\"qna\"][split_index:]\n",
    "\n",
    "    def format_data(data):\n",
    "        formatted = []\n",
    "        for item in data:\n",
    "            question = clean_text(item[\"question\"])\n",
    "            answer = clean_text(item[\"answer\"])\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "                {\"role\": \"assistant\", \"content\": answer},\n",
    "            ]\n",
    "            formatted.append({\"messages\": messages})\n",
    "        return formatted\n",
    "\n",
    "    def save_to_csv(data, csv_file):\n",
    "        with open(\n",
    "            os.path.join(output_folder, csv_file),\n",
    "            mode=\"w\",\n",
    "            newline=\"\",\n",
    "            encoding=\"utf-8\",\n",
    "        ) as file:\n",
    "            writer = csv.writer(file, quoting=csv.QUOTE_MINIMAL, escapechar=\"\\\\\")\n",
    "            writer.writerow([\"messages\"])\n",
    "            for row in data:\n",
    "                writer.writerow([json.dumps(row, ensure_ascii=False)])\n",
    "\n",
    "    # Format and save training and testing data\n",
    "    save_to_csv(format_data(train_data), train_file)\n",
    "    save_to_csv(format_data(test_data), test_file)\n",
    "\n",
    "    print(f\"Training data saved to {os.path.join(output_folder, train_file)}.\")\n",
    "    print(f\"Testing data saved to {os.path.join(output_folder, test_file)}.\")\n",
    "\n",
    "\n",
    "# Process sleep and car files separately\n",
    "process_json_file(\n",
    "    SLEEP_DATA_FILE, OUTPUT_FOLDER, TRAIN_SLEEP_FILE, TEST_SLEEP_FILE, TRAIN_RATIO\n",
    ")\n",
    "process_json_file(\n",
    "    CAR_DATA_FILE, OUTPUT_FOLDER, TRAIN_CAR_FILE, TEST_CAR_FILE, TRAIN_RATIO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucki\\anaconda3\\envs\\webai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting ',' delimiter: line 1 column 430 (char 429)\n",
      "Problematic JSON: {\"messages\": [{\"role\": \"user\", \"content\": \"How does sleep quality affect cognitive function , memory consolidation , and learning capacity ?\"}, {\"role\": \"assistant\", \"content\": \"Sleep quality affects cognitive function , memory consolidation , and learning capacity in several ways . A good sleep quality , particularly slow - wave sleep , is considered important for memory consolidation , which is sometimes referred to as \\\\\" sleep - dependent memory processing . \\\\\" Impaired memory consolidation has been seen in individuals with primary insomnia , who do not perform as well as those who are healthy in memory tasks following a period of sleep . Slow - wave sleep improves declarative memory , including semantic and episodic memory . On the other hand , chronic sleep deficiency or insomnia can lead to high anxiety , irritability , erratic behavior , poor cognitive functioning and performance , and psychotic episodes . Insufficient sleep has also been linked to weight gain , high blood pressure , diabetes , depression , heart disease , and strokes . In summary , good sleep quality is essential for optimal cognitive function , memory consolidation , and learning capacity . Poor sleep quality or insufficient sleep can negatively impact these areas , leading to various cognitive and emotional impairments , as well as physical health issues .\"}]}\n",
      "Error decoding JSON: Expecting ',' delimiter: line 1 column 258 (char 257)\n",
      "Problematic JSON: {\"messages\": [{\"role\": \"user\", \"content\": \"What are the historical origins of the coupe body style , and how has it evolved over time ?\"}, {\"role\": \"assistant\", \"content\": \"The coupé body style has its origins in horse - drawn carriages , with the term \\\\\" coupé \\\\\" coming from the French word for \\\\\" cut . \\\\\" Initially , it referred to a variant of the coupé carriage in the 19th century , which had an enclosed passenger compartment and a separate , exposed area for the driver . This design was later adapted for automobiles , resulting in the creation of the coupe de ville in the early 20th century . The coupe de ville , also known as a town car or sedanca de ville , featured an external or open - topped driver 's position and an enclosed area for passengers . The term \\\\\" de ville \\\\\" means \\\\\" for town \\\\\" in French , indicating that the vehicle was intended for use in urban environments or short distances . Over time , the coupe body style has evolved , and the term \\\\\" coupé \\\\\" is now often used to describe a two - door vehicle with a fixed roof and a sloping rear window . The historical three - box sedan design , characterized by a separate engine compartment , passenger compartment , and trunk , has been the standard shape of automobiles for decades . However , by 2018 , the three - box sedan began to wane in popularity in the United States , marking a shift in the evolution of the coupe body style and automobile design in general .\"}]}\n",
      "Error decoding JSON: Expecting ',' delimiter: line 1 column 935 (char 934)\n",
      "Problematic JSON: {\"messages\": [{\"role\": \"user\", \"content\": \"What are the key design and engineering differences between sedans and coupes ?\"}, {\"role\": \"assistant\", \"content\": \"The key design difference between sedans and coupes is the number of passenger compartments . Sedans , also known as three - box designs , have three separate compartments for the engine , passengers , and cargo . In contrast , coupes , such as coupés de ville , typically have two separate compartments : one for the engine and one for the passengers . In terms of engineering , sedans usually have a B - pillar to support the roof and provide structural rigidity , while coupés de ville may or may not have a B - pillar , depending on the specific design . Additionally , coupés de ville often have a longer wheelbase and a more elongated body style than sedans , providing more legroom and a more luxurious feel for the passengers . It is worth noting that the terms \\\\\" sedan \\\\\" and \\\\\" coupe \\\\\" can sometimes be used loosely and may overlap in meaning depending on the manufacturer or country . However , the general distinction between the two lies in the number of separate passenger compartments and the overall body style .\"}]}\n",
      "Mean token length: 164.34\n",
      "Median token length: 154.00\n",
      "Standard deviation of token length: 58.34\n",
      "Plots and summary have been saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import re\n",
    "\n",
    "# Load the data\n",
    "train_sleep = pd.read_csv(\"processed/train_sleep.csv\")\n",
    "train_car = pd.read_csv(\"processed/train_car.csv\")\n",
    "\n",
    "# Combine the datasets\n",
    "all_data = pd.concat([train_sleep, train_car])\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "def extract_text(row):\n",
    "    try:\n",
    "        messages = json.loads(row)[\"messages\"]\n",
    "        return \" \".join([clean_text(msg[\"content\"]) for msg in messages])\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        print(f\"Problematic JSON: {row}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# Apply text extraction and get token lengths\n",
    "all_data[\"text\"] = all_data[\"messages\"].apply(extract_text)\n",
    "all_data[\"token_length\"] = all_data[\"text\"].apply(lambda x: len(tokenizer.encode(x)))\n",
    "\n",
    "# Filter out rows with empty text\n",
    "all_data = all_data[all_data[\"text\"] != \"\"]\n",
    "\n",
    "# Plot token length distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(all_data[\"token_length\"], kde=True)\n",
    "plt.title(\"Distribution of Token Lengths\")\n",
    "plt.xlabel(\"Token Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"token_length_distribution.png\")\n",
    "plt.close()\n",
    "\n",
    "# Plot normal probability plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "stats.probplot(all_data[\"token_length\"], dist=\"norm\", plot=plt)\n",
    "plt.title(\"Normal Probability Plot of Token Lengths\")\n",
    "plt.savefig(\"token_length_qq_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Calculate and print statistics\n",
    "mean_length = np.mean(all_data[\"token_length\"])\n",
    "median_length = np.median(all_data[\"token_length\"])\n",
    "std_dev = np.std(all_data[\"token_length\"])\n",
    "\n",
    "print(f\"Mean token length: {mean_length:.2f}\")\n",
    "print(f\"Median token length: {median_length:.2f}\")\n",
    "print(f\"Standard deviation of token length: {std_dev:.2f}\")\n",
    "\n",
    "# Plot box plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=all_data[\"token_length\"])\n",
    "plt.title(\"Box Plot of Token Lengths\")\n",
    "plt.xlabel(\"Token Length\")\n",
    "plt.savefig(\"token_length_boxplot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Statistic\": [\"Mean\", \"Median\", \"Standard Deviation\"],\n",
    "        \"Value\": [mean_length, median_length, std_dev],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Save summary to CSV\n",
    "summary.to_csv(\"token_length_summary.csv\", index=False)\n",
    "\n",
    "print(\"Plots and summary have been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 997.69ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<?, ?ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep dataset successfully pushed to the Hugging Face Hub!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1001.27ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 999.83ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car dataset successfully pushed to the Hugging Face Hub!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "from huggingface_hub import HfApi, HfFolder\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the Hugging Face token from the environment variable\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "if not hf_token:\n",
    "    raise ValueError(\"Please set the HF_TOKEN environment variable in the .env file\")\n",
    "\n",
    "# Save the token to the Hugging Face folder\n",
    "HfFolder.save_token(hf_token)\n",
    "\n",
    "# Define the file paths\n",
    "train_sleep_file = \"processed/train_sleep.csv\"\n",
    "test_sleep_file = \"processed/test_sleep.csv\"\n",
    "train_car_file = \"processed/train_car.csv\"\n",
    "test_car_file = \"processed/test_car.csv\"\n",
    "\n",
    "# Function to load and convert CSV to Dataset\n",
    "def load_dataset(train_file, test_file):\n",
    "    train_df = pd.read_csv(train_file)\n",
    "    test_df = pd.read_csv(test_file)\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "    return DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "\n",
    "\n",
    "# Load the sleep and car datasets\n",
    "sleep_dataset = load_dataset(train_sleep_file, test_sleep_file)\n",
    "car_dataset = load_dataset(train_car_file, test_car_file)\n",
    "\n",
    "# Push the sleep dataset to Hugging Face Hub\n",
    "sleep_dataset.push_to_hub(\"thinkersloop/sleep-dataset-llm\", private=False)\n",
    "print(\"Sleep dataset successfully pushed to the Hugging Face Hub!\")\n",
    "\n",
    "# Push the car dataset to Hugging Face Hub\n",
    "car_dataset.push_to_hub(\"thinkersloop/car-dataset-llm\", private=False)\n",
    "print(\"Car dataset successfully pushed to the Hugging Face Hub!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
