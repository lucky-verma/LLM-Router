{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Classification on PreTrained BART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Query: What's the impact of sleep deprivation on cognitive function?\n",
      "Classified as: sleep, score: 0.9878818392753601\n",
      "\n",
      "--------------------------------------------------\n",
      "Query: Can you explain the history of the internal combustion engine?\n",
      "Classified as: car, score: 0.856473445892334\n",
      "\n",
      "--------------------------------------------------\n",
      "Query: How does REM sleep affect memory consolidation?\n",
      "Classified as: sleep, score: 0.9879106879234314\n",
      "\n",
      "--------------------------------------------------\n",
      "Query: What are the main components of an electric vehicle's drivetrain?\n",
      "Classified as: car, score: 0.9461274147033691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# check if gpu is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the zero-shot classification model\n",
    "classifier = pipeline(\"zero-shot-classification\", \n",
    "                      model=\"facebook/bart-large-mnli\",\n",
    "                      device=device,\n",
    "                      )\n",
    "\n",
    "# Define the labels\n",
    "candidate_labels = [\"sleep\", \"car\"]\n",
    "\n",
    "# Function to classify the topic of the query\n",
    "def classify_query(text: str) -> str:\n",
    "    result = classifier(text, candidate_labels)\n",
    "    return result  # Return the most likely topic\n",
    "\n",
    "\n",
    "# Test the classifier\n",
    "queries = [\n",
    "    \"What's the impact of sleep deprivation on cognitive function?\",\n",
    "    \"Can you explain the history of the internal combustion engine?\",\n",
    "    \"How does REM sleep affect memory consolidation?\",\n",
    "    \"What are the main components of an electric vehicle's drivetrain?\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    result = classify_query(query)\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Classified as: {result['labels'][0]}, score: {result['scores'][0]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `TODO`: Synthetic Data Generation for fine tuning - router model\n",
    "\n",
    "When developing a robust multi-model LLM system, one critical component is the router model, which directs queries to the appropriate domain-specific model. For our system, we use a zero-shot classification model (BART-large-mnli) to classify queries into either \"sleep\" or \"car\" categories. However, the effectiveness of this router model heavily depends on the quality and quantity of labeled training data.\n",
    "\n",
    "## Training with Existing Datasets\n",
    "\n",
    "If we have access to high-quality, labeled datasets for sleep and car topics, we can directly use these datasets to train our zero-shot classification model. These datasets should contain a variety of questions and answers related to each domain, ensuring that the model learns to accurately classify a wide range of queries.\n",
    "\n",
    "For example:\n",
    "    * Sleep Dataset: Contains questions about sleep science, sleep disorders, sleep hygiene, and related topics.\n",
    "    * Car Dataset: Encompasses questions about car history, automotive technology, car maintenance, and more.\n",
    "\n",
    "## Generating Synthetic Data with Advanced LLMs\n",
    "\n",
    "In cases where existing datasets are insufficient or unavailable, we can leverage advanced language models like GPT-4 to generate high-quality synthetic datasets. This approach involves using GPT-4 to create realistic and contextually accurate questions and answers for both sleep and car domains. The generated data can then be labeled and used to train the router model.\n",
    "\n",
    "## Steps to Generate Synthetic Data\n",
    "\n",
    "1. Define Prompts for Data Generation:\n",
    "    * Create prompts that instruct GPT-4 to generate questions and answers related to sleep and car topics.\n",
    "    * Example prompts:\n",
    "        * \"Generate 10 questions and answers about sleep science.\"\n",
    "        * \"Create 10 questions and answers about car maintenance.\"\n",
    "2. Generate Data:\n",
    "    * Use GPT-4 to generate the synthetic data based on the defined prompts.\n",
    "    * Ensure the generated data covers a wide range of topics within each domain to improve the robustness of the router model.\n",
    "3. Label the Data:\n",
    "    * Label each generated question with the appropriate category (\"sleep\" or \"car\").\n",
    "    * This labeling can be automated if the prompts are designed to include the category in the output.\n",
    "4. Train the Router Model:\n",
    "    * Combine the synthetic data with any existing labeled data.\n",
    "    * Train the zero-shot classification model on this combined dataset to improve its accuracy and generalization.\n",
    "\n",
    "NOTE: This process can be used for Memorization tasks to fine tune LLMs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wabai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
